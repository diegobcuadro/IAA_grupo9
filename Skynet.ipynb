{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0YPHj-1XfEg5"
   },
   "source": [
    "# Diplodatos Kaggle Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cteRVOqjfEg9"
   },
   "source": [
    "We present this peace of code to create the baseline for the competition, and as an example of how to deal with these kind of problems. The main goals are that you:\n",
    "\n",
    "1. Learn\n",
    "1. Try different models and see which one fits the best the given data\n",
    "1. Get a higher score than the given one in the current baseline example\n",
    "1. Try to get the highest score in the class :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "M43MsWa-fEg_",
    "outputId": "0f4fa225-fadb-40af-ba5d-6477fdc06a8d"
   },
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vOTKxfMofPgx"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lnzx8RNlfTMQ"
   },
   "outputs": [],
   "source": [
    "# DATA_DIRECTORY = '/content/drive/My Drive/Colab/AAKaggle/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "s9gl4qCefVM4",
    "outputId": "454ae517-3c69-4fa0-a151-72a1c133129a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U8ja8eSn3u3w"
   },
   "outputs": [],
   "source": [
    "def transform_data(train_data_fname, test_data_fname):\n",
    "    df_train = pd.read_csv(train_data_fname)\n",
    "    df_train['is_train_set'] = 1\n",
    "    df_test = pd.read_csv(test_data_fname)\n",
    "    df_test['is_train_set'] = 0\n",
    "    \n",
    "    # we  get the TripType for the train set. To do that, we group by VisitNumber and\n",
    "    # then we get the max (or min or avg)\n",
    "    \n",
    "    df_train[df_train.TripType.isna()] = df_train.TripType.max()\n",
    "    y = df_train.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max().TripType\n",
    "    \n",
    "    y_mean = y.mean()\n",
    "    y = y.fillna(y_mean)\n",
    "    print(y.shape)\n",
    "\n",
    "    # we remove the TripType now, and concat training and testing data\n",
    "    # the concat is done so that we have the same columns for both datasets\n",
    "    # after one-hot encoding\n",
    "    df_train = df_train.drop(\"TripType\", axis=1)\n",
    "    df = pd.concat([df_train, df_test])\n",
    "    \n",
    "    \n",
    "    # the next three operations are the ones we have just presented in the previous lines\n",
    "    \n",
    "    #df.dropna(inplace= True)\n",
    "    extra = df.copy()\n",
    "    Department_num_of_products=dict(df.groupby('DepartmentDescription')['Upc'].count())\n",
    "    extra['num_of_products_for_department']=df['DepartmentDescription'].apply(lambda x:Department_num_of_products.get(x))\n",
    "    \n",
    "    # drop the columns we won't use (it may be good to use them somehow)\n",
    "    df = df.drop([\"Upc\", \"FinelineNumber\"], axis=1)\n",
    "\n",
    "    # one-hot encoding for the DepartmentDescription\n",
    "    df = pd.get_dummies(df, columns=[\"DepartmentDescription\"], dummy_na=True)\n",
    "\n",
    "    # now we add the groupby values\n",
    "    df = df.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).sum()\n",
    "    \n",
    "    # Generate new feature: weekend\n",
    "    \n",
    "    weekend_dict = {\n",
    "    'Monday': 0, \n",
    "    'Tuesday': 0,\n",
    "    'Wednesday': 0,\n",
    "    'Thursday': 0,\n",
    "    'Friday': 0,\n",
    "    'Saturday': 1,\n",
    "    'Sunday': 1,\n",
    "    }\n",
    "\n",
    "    df['Weekend'] = df['Weekday'].replace(weekend_dict)\n",
    "    \n",
    "    # finally, we do one-hot encoding for the Weekday\n",
    "    df = pd.get_dummies(df, columns=[\"Weekday\"], dummy_na=True)\n",
    "    \n",
    "    # Create new feature\n",
    "    aux_data = extra.copy()\n",
    "    products_per_visit = aux_data.groupby(['VisitNumber'])['Upc'].count()\n",
    "    products_per_visit_dict=dict(products_per_visit)\n",
    "    df['quantity_products_per_VisitNumber']=df['VisitNumber'].apply(lambda x:products_per_visit_dict.get(x,0))\n",
    "\n",
    "\n",
    "    # Obtain maximun values of Upc and FineLineNumber and create new features\n",
    "    getMax = extra.copy()\n",
    "    getMax = getMax.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).max()\n",
    "    df['UpcMax'] = getMax['Upc']\n",
    "    df['FinelineNumberMax'] = getMax['FinelineNumber']\n",
    "    getMin = extra.copy()\n",
    "    getMin = getMin.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).min()\n",
    "    df['UpcMin'] = getMin['Upc']\n",
    "    df['FinelineNumberMin'] = getMin['FinelineNumber']\n",
    "    \n",
    "    \n",
    "    # df['num_of_products_for_department'] = extra['num_of_products_for_department']\n",
    "    # df['UpcMax'] = extra.groupby([\"VisitNumber\", \"Weekday\"], as_index=False)['Upc']\n",
    "    # df['FinelineNumberMax'] = extra.groupby([\"VisitNumber\", \"Weekday\"], as_index=False)['FinelineNumber']\n",
    "    # df['num_of_products_for_department'] = extra.groupby([\"VisitNumber\", \"Weekday\"], as_index=False)['num_of_products_for_department']\n",
    "\n",
    "    def getValue(value):\n",
    "      if isinstance(value,float):\n",
    "        return value\n",
    "      else:\n",
    "        if isinstance(value,np.ndarray):\n",
    "          if value.size == 0:\n",
    "            return np.nan\n",
    "          else:\n",
    "            return np.take(value,0)\n",
    "\n",
    "\n",
    "\n",
    "    extra = extra.groupby([\"VisitNumber\", \"Weekday\"], as_index=False).agg({'Upc' : lambda x: x.mode(), 'FinelineNumber' : lambda x: x.mode(),\n",
    "                                                                           'num_of_products_for_department' : lambda x: x.mode()})\n",
    "    \n",
    "    df['UpcMode'] = extra['Upc'].apply(getValue)\n",
    "    df['FinelineNumberMode'] = extra['FinelineNumber'].apply(getValue)\n",
    "    df['num_of_products_for_departmentMode'] = extra['num_of_products_for_department'].apply(getValue)\n",
    "\n",
    "    # Fill NaN values with means\n",
    "    df_mean = df.mean()\n",
    "    df = df.fillna(df_mean)\n",
    "    print(df.shape)\n",
    "    \n",
    "    \n",
    "    # get train and test back\n",
    "    df_train = df[df.is_train_set != 0]\n",
    "    df_test = df[df.is_train_set == 0]\n",
    "    \n",
    "    X = df_train.drop([\"is_train_set\"], axis=1)\n",
    "    yy = None\n",
    "    XX = df_test.drop([\"is_train_set\"], axis=1)\n",
    "    \n",
    "    print(X.shape)\n",
    "    print(XX.shape)\n",
    "\n",
    "    return X, y, XX, yy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CIVNOA0JfEhZ"
   },
   "source": [
    "Load the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "svj43gikfEhc",
    "outputId": "a82fad96-fb6a-44da-9917-4bd769f0297d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67029,)\n",
      "(95674, 89)\n",
      "(67029, 88)\n",
      "(28645, 88)\n"
     ]
    }
   ],
   "source": [
    "X, y, XX, yy = transform_data('../data/train.csv', '../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J1onM2h_fEhl"
   },
   "source": [
    "Create the model and evaluate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lkJh9gxYfEhn"
   },
   "outputs": [],
   "source": [
    "# split training dataset into train and \"validation\" \n",
    "# (we won't be using validation set in this example, because of the cross-validation;\n",
    "# but it could be useful for you depending on your approach)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLQ5aIS2fEh3"
   },
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "clfe = ensemble.RandomForestClassifier(random_state=2, bootstrap=False, min_samples_leaf=1, min_samples_split=10, n_estimators=300, criterion='gini', max_features=18, n_jobs=-1)\n",
    "\n",
    "clfe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "SEtjhiycfEh-",
    "outputId": "c09db65a-1048-4cd2-ce14-5ae58128ea70",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 99.109569 \n"
     ]
    }
   ],
   "source": [
    "predictions = clfe.predict(X_train)\n",
    "print ('Accuracy: %f ' % ((np.sum(y_train == predictions))/float(y_train.size)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "XsQDDLrpfEiE",
    "outputId": "c7241475-01a8-49b1-ca54-de6f6ce349c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 72.523866 \n"
     ]
    }
   ],
   "source": [
    "predictions = clfe.predict(X_valid)\n",
    "print ('Accuracy: %f ' % ((np.sum(y_valid == predictions))/float(y_valid.size)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wKhEWBq-fEiK"
   },
   "outputs": [],
   "source": [
    "yy = clfe.predict(XX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jHwhd8FhfEiR"
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(list(zip(XX.VisitNumber, yy)), columns=[\"VisitNumber\", \"TripType\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ez46uZDVfEiY"
   },
   "outputs": [],
   "source": [
    "submission.to_csv('../data/submission.csv', header=True, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "csFy_zylf61Q"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "kaggle",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
